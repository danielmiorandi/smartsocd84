\subsection{Monitoring}
\subsubsection{Functionality and Features}
The implementation of the monitoring component is based upon three basic components:
• Modules gathering and publishing the relevant information;
• Modules consuming the monitoring related information;
• Information dissemination infrastructure.
In particular, local agents collect specific information regarding the liveliness and health status of each component and communicate with the infrastructure via lightweight java/js clients. The monitoring infrastructure provides scalable support to the collection of local agents feeds. A monitoring dashboard represents the main consumer of monitoring data generated by the agents and dispatched through the monitoring infrastructure.
The implementation shipped with the i-locate toolkit, whose architecture is sketched in Figure 4, is based on the logstash open source framework , which presents very good support for collection of logs in various schemas/formats, and has a large number of plugins available for the most widely used commercial frameworks. The usage of logstash is coupled with a redis broker for additional scalability and elasticsearch for indexing and persistence. The usage of redis broker is optional, currently not foreseen for the limited-scale i-locate pilots.
Aggregated and curated logs are stored in the elastic database and can be queried via standard interfaces, enabling technical supporting partners to develop their own ad hoc monitoring dashboard or to integrate with legacy ones. The default option for the i-locate toolkit is to use Kibana, a flexible dashboard which supports seamless integration with elasticsearch and presents basic, yet sufficient analytics functionality. A sample dashboard is reported in Figure 5.

The goal of the monitoring component is to enabler system administrators to monitor the liveliness of the SmartSociety platform components, possibly distributed across multiple servers. Target users of the functionality exposed are therefore system administrators at pilot sites and i-locate technical supporting partners.
The main expected usage is for troubleshooting in case of platform malfunctioning, alerts and warnings. In the long term, it can enable the deployment of self-healing mechanisms.
\subsubsection{Implementation}
The monitoring framework is based on Logstash\footnote{{\tt http://logstash.net/}}, an open-source tool for managing events and logs. Logstash can be used to collect logs, parse them, and store them for later use (e.g., search and visualization). %Speaking of searching, Logstash comes with a web interface for searching and drilling into all of the logs collected over time.
It is possible to define what information shall be permanently stored and processed by the monitoring framework. In particular, it is possible to integrate:
\begin{itemize}
\item System logs: these logs correspond to logs, which are generated by the various system components such as, e.g., web servers, application servers. 
\item Application logs: specific logs that are produced by applications, and require a constant integration for debugging and monitoring purposes.
\item Monitoring information: any agent that can be configured to deliver data to the Logstash infrastructure.
\end{itemize}

In all three cases, a Logstash shipper is used to connect the specific source of data to Logstash. Specific shippers already exists for some widely used system components such as, e.g., web servers, databases, etc., while custom shippers can be created for specific cases. In the case of SmartSociety, we created a dedicated shipper to collect the events produced by the various platform components.\\
The following component is a Redis Broker. This is an optional component that can be used in order to scale the system to large volumes of events and data. Based on Redis, data is indexed in order to prepare it for optimal searching and querying. Once the data is indexed, it is stored in an ElasticSearch cluster for storage and search. 
Starting from the data stored in ElasticSearch, it is possible to build queries on scale to explore the collected data. We decided to use Kibana\footnote{{\tt https://www.elastic.co/products/kibana}} as the tool to create and visualize queries on the collected data. Kibana is fully integrated with ElasticSearch, and allows to easily explore and analyze large volumes of data. A sample visualization is shown in~\ref{fig:kibana}.  The metrics and specific charts can be configured dynamically by the administrator of the platform.
\subsubsection{Interfaces, Endpoints and Resources Exposed}
The Monitoring component functionality is accessible through the Kibana GUI. Elasticsearch Search APIs can be used for integration with legacy visualization dashboards. Otherwise, a Kibana dashboard is shipped.
\subsubsection{Repository}
Not applicable.
\todo{add to the repo empty project with wiki with instructions on how to build it}